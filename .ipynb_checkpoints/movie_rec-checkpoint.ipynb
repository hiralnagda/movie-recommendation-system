{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import surprise\n",
    "from surprise import Reader, Dataset, SVD, evaluate, SlopeOne, KNNBasic, KNNWithMeans\n",
    "from surprise import accuracy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from surprise.model_selection import train_test_split\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('/Users/yashnisar/Downloads/ratings.csv', sep=',', usecols=['userId', 'movieId', 'rating','timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data such that for each user, randomly = 80% of his/her ratings as the training ratings, and use the remaining 20% ratings as testing ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.DataFrame(columns = ['userId', 'movieId', 'rating','timestamp'])\n",
    "test_set = pd.DataFrame(columns = ['userId', 'movieId', 'rating','timestamp'])\n",
    "for user in ratings['userId'].unique():\n",
    "    temp = ratings.loc[ratings['userId'] == user]\n",
    "    train, test = train_test_split(temp, test_size=0.2)\n",
    "    train_set = train_set.append(train, ignore_index=True)\n",
    "    test_set = test_set.append(test, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader()\n",
    "data = Dataset.load_from_df(train_set[['userId', 'movieId', 'rating']], reader)\n",
    "trainset = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_items(predictions):\n",
    "    results = {}\n",
    "    for uid, iid, true_r, est, details in predictions:\n",
    "        if uid in results:\n",
    "            results[uid].append((iid, est))\n",
    "        else:\n",
    "            results[uid] = [(iid, est)]\n",
    "\n",
    "    for uid in results:\n",
    "        results[uid].sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "   \n",
    "    user_dict = {}\n",
    "    for uid, iid, true_r, est, details in predictions:\n",
    "        if uid in user_dict:\n",
    "            user_dict[uid].append((est, true_r))\n",
    "        else:\n",
    "            user_dict[uid] = [(est, true_r)]\n",
    "\n",
    "    precisions = {}\n",
    "    recalls = {}\n",
    "    for uid in user_dict:\n",
    "        user_dict[uid].sort(key=lambda x: x[0], reverse=True)\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_dict[uid])\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_dict[uid][:k])\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_dict[uid][:k])\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "\n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_dcg_score(predictions, k=10, gains=\"exponential\"):\n",
    "    \n",
    "    user_dict = {}\n",
    "    for uid, iid, true_r, est, details in predictions:\n",
    "        if uid in user_dict:\n",
    "            user_dict[uid].append((est, true_r))\n",
    "        else:\n",
    "            user_dict[uid] = [(est, true_r)]\n",
    "\n",
    "    dcg_score = {}\n",
    "    norm_dcg_score = {}\n",
    "    for uid in user_dict:\n",
    "        est = []\n",
    "        true_r = []\n",
    "        user_dict[uid].sort(key=lambda x: x[0], reverse=True)\n",
    "        user_dict[uid] = user_dict[uid][:k]\n",
    "        \n",
    "        for x, y in user_dict[uid]:\n",
    "            est.append(x)\n",
    "            true_r.append(y)\n",
    "\n",
    "        est = np.array(est)\n",
    "        true_r = np.array(true_r)\n",
    "        \n",
    "        order = np.argsort(est)[::-1]\n",
    "        y_true = np.take(true_r, order[:k])\n",
    "        \n",
    "        if gains == \"exponential\":\n",
    "            gain_val = 2 ** y_true - 1\n",
    "        elif gains == \"linear\":\n",
    "            gain_val = y_true\n",
    "        else:\n",
    "            raise ValueError(\"Invalid gains option.\")\n",
    "        \n",
    "        discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "        dcg_score[uid] = np.sum(gain_val / discounts)\n",
    "        \n",
    "        \n",
    "        #-------code for norm dcg score---------------------------------\n",
    "        order = np.argsort(true_r)[::-1]\n",
    "        y_true = np.take(true_r, order[:k])\n",
    "        \n",
    "        if gains == \"exponential\":\n",
    "            gain_val = 2 ** y_true - 1\n",
    "        elif gains == \"linear\":\n",
    "            gain_val = y_true\n",
    "        else:\n",
    "            raise ValueError(\"Invalid gains option.\")\n",
    "        \n",
    "        discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "        norm_dcg_score[uid] = dcg_score[uid]/np.sum(gain_val / discounts)\n",
    "    \n",
    "    return norm_dcg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_names = ['SVD', 'SlopeOne', 'KNN Basic','KNN with Means']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SVD' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-54ed6761d9de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSVD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSlopeOne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKNNBasic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKNNWithMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n Algorithm:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SVD' is not defined"
     ]
    }
   ],
   "source": [
    "for index, algo in enumerate([SVD(), SlopeOne(), KNNBasic(), KNNWithMeans()]):\n",
    "    print(\"\\n Algorithm:\", algo_names[index])\n",
    "    algo.fit(trainset)\n",
    "    predictions = []\n",
    "    for _, row in test_set.iterrows():\n",
    "        predictions.append(algo.predict(row.userId, row.movieId, row.rating))\n",
    "    print(\"RMSE\", accuracy.rmse(predictions, verbose=False))\n",
    "    print(\"MAE\", accuracy.mae(predictions, verbose=False))\n",
    "    # print(predictions)\n",
    "    print(norm_dcg_score(predictions, k=10, gains=\"exponential\"))\n",
    "    top_recommendations = recommend_items(predictions)\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=10, threshold=4)\n",
    "    avg_prec = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "    avg_recall = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "    fscore = 2 * (avg_prec * avg_recall)/ (avg_prec + avg_recall)\n",
    "    print(\"Fscore:\", fscore)\n",
    "    print(\"Average Precision:\", avg_prec)\n",
    "    print(\"Average Recall:\", avg_recall)\n",
    "    print(\"Top recommendations: \", top_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
